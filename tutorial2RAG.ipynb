{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW5J0EOLZU7Q",
        "outputId": "1ea19708-a6d6-4636-802e-83e5d424d32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.5/136.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHzxjDPapHw",
        "outputId": "e6373321-52c9-473d-9e9b-401e7df28f88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU \"langchain[openai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGzxqdicate4",
        "outputId": "f27f6932-2a6d-48fc-da12-18fc3329700d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWnqwXDAa24o",
        "outputId": "7eae0971-6bf2-4337-d43d-eaccc62851b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "_JockN6ja8fj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ],
      "metadata": {
        "id": "jtCu07AcbAim"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kZl8MblbGNM",
        "outputId": "9708f699-35d0-4e3c-972c-95fa1087a9bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.1/417.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-pinecone pinecone-notebooks"
      ],
      "metadata": {
        "id": "vv0HVq8gbzDg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ.pop(\"PINECONE_API_KEY\", None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "uabDU-6te0bX",
        "outputId": "32b793a4-b378-4e8f-e84e-b0e45ed61e27"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import getpass import os  from pinecone import Pinecone, ServerlessSpec  if not os.getenv(\"PINECONE_API_KEY\"):     os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")  pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")  pc = Pinecone(api_key=pinecone_api_key)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "if not os.getenv(\"PINECONE_API_KEY\"):\n",
        "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
        "\n",
        "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ],
      "metadata": {
        "id": "19SCtiCZfXKf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "index_name = \"langchain-test-index\"  # change if desired\n",
        "\n",
        "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "\n",
        "if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=3072,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
        "        time.sleep(1)\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "X5QR8InBefEN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "NbDnselGgEC4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKhq4gjtgaH2",
        "outputId": "ab99cb5b-04b5-49b9-c792-89770e4355b1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bc9c0a90-d686-456c-aebf-b670d83cfc90',\n",
              " 'b28471cf-e389-4346-aca7-44e8274741c6',\n",
              " '088f6676-24e7-47f3-a6eb-f6c0e93225aa',\n",
              " '9eac1693-b5cf-4010-8e5b-09de6e7a598a',\n",
              " '6f528616-0ffa-4294-a293-59a8ff54514e',\n",
              " '50ad5b9c-a40e-466c-904d-3eb834f8911d',\n",
              " '655cec06-9119-4621-beb4-a1a4456b0772',\n",
              " 'e5de9c82-0824-44a9-9265-8ded2ddc93ea',\n",
              " '59aeee8c-412d-46dd-8789-59adcb929a6f',\n",
              " 'f9329d99-553f-4062-a273-43f815a3f71b']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "# Load and chunk contents of the blog\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Index chunks\n",
        "_ = vector_store.add_documents(documents=all_splits)\n",
        "\n",
        "# Define prompt for question-answering\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "\n",
        "# Define state for application\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Define application steps\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "\n",
        "# Compile application and test\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCCCbkjZgLdy",
        "outputId": "60687457-1447-461f-a397-31b7a784526a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av_ig2acgRnB",
        "outputId": "84328702-4464-42be-981b-623c3999115c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task decomposition is the process of breaking down a complex task into smaller, manageable steps or subtasks. This can be achieved through prompting techniques like Chain of Thought (CoT) or by using task-specific instructions, allowing the model to plan and think step-by-step. The goal is to make difficult tasks easier to handle and to clarify the model's reasoning process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Only keep post title, headers, and content from the full HTML.\n",
        "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "assert len(docs) == 1\n",
        "print(f\"Total characters: {len(docs[0].page_content)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SLG-AFOhky2",
        "outputId": "c850dece-a3e7-4538-d978-beeb7c31ead1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters: 43130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8zyO3Twhp2I",
        "outputId": "7730170f-a58a-4ac1-8a5e-b0cbe25b4944"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "      LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
            "Agent System Overview#\n",
            "In\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # chunk size (characters)\n",
        "    chunk_overlap=200,  # chunk overlap (characters)\n",
        "    add_start_index=True,  # track index in original document\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVtJ2WkEhtnJ",
        "outputId": "7bb0bd0a-11dd-40e7-9746-62ff7b64a853"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split blog post into 66 sub-documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_ids = vector_store.add_documents(documents=all_splits)\n",
        "\n",
        "print(document_ids[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY2KojSehvQ6",
        "outputId": "c05be389-07ed-4fe2-b654-0cbb0c3f532d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d4fa5a58-5049-4c2c-93e5-42f301452c87', '19d3083a-3357-4233-816e-0fb5f2c20684', 'ccd1f76d-5408-415d-a5ac-03549c2ef14d']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
        ").to_messages()\n",
        "\n",
        "assert len(example_messages) == 1\n",
        "print(example_messages[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiV9mRNIh0UA",
        "outputId": "d5137315-e50b-4c6a-b95f-84a11e21e92e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: (question goes here) \n",
            "Context: (context goes here) \n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str"
      ],
      "metadata": {
        "id": "1BHhagUih34b"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}"
      ],
      "metadata": {
        "id": "xqHSpCKNh54M"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "tWU7_hyYh8GV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "9ecYdxMCh-N8",
        "outputId": "56227990-d341-4279-899a-cb46bc014aa8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
        "\n",
        "print(f'Context: {result[\"context\"]}\\n\\n')\n",
        "print(f'Answer: {result[\"answer\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIleZX3_iA7N",
        "outputId": "b57b3648-509e-4573-cfa4-36791107e967"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: [Document(id='ccd1f76d-5408-415d-a5ac-03549c2ef14d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='bce294a3-b411-4a24-a436-492e9c9bcf6d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='2085ae71-ba0f-47e3-8145-d77c05ac97a7', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='53bc4979-b2ad-4539-8db9-e29e94fc073e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192.0}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')]\n",
            "\n",
            "\n",
            "Answer: Task Decomposition is the process of breaking down a complicated task into smaller, manageable steps to enhance problem-solving. This can be achieved using prompting techniques like \"Chain of Thought\" (CoT), which encourages models to think step by step. It can also involve specific instructions or human inputs to help clarify subgoals and outline tasks effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulUhRrMSiFZI",
        "outputId": "c5d05fdf-37a6-47e0-8844-24a9b24e492e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'retrieve': {'context': [Document(id='ccd1f76d-5408-415d-a5ac-03549c2ef14d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='bce294a3-b411-4a24-a436-492e9c9bcf6d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='2085ae71-ba0f-47e3-8145-d77c05ac97a7', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='53bc4979-b2ad-4539-8db9-e29e94fc073e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192.0}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'Task decomposition is the process of breaking down complex tasks into smaller, manageable steps to enhance problem-solving efficiency. It typically involves using techniques like Chain of Thought (CoT), where a model is prompted to \"think step by step.\" This approach allows for better planning and interpretation of the model\\'s reasoning.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for message, metadata in graph.stream(\n",
        "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
        "):\n",
        "    print(message.content, end=\"|\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5hzk9xSiImt",
        "outputId": "cef3166b-15ac-4b4e-a7b5-850036a26c40"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|Task| decomposition| is| the| process| of| breaking| down| complicated| tasks| into| smaller|,| manageable| steps|,| enhancing| the| ability| to| plan| and| execute| them| effectively|.| Techniques| like| Chain| of| Thought| (|Co|T|)| encourage| models| to| \"|think| step| by| step|,\"| while| methods| like| Tree| of| Thoughts| further| explore| multiple| reasoning| possibilities| at| each| step|.| De|composition| can| also| be| guided| by| prompts|,| task|-specific| instructions|,| or| human| input|.||"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Use three sentences maximum and keep the answer as concise as possible.\n",
        "Always say \"thanks for asking!\" at the end of the answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\"\"\"\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "m76KwSILiNWo"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_documents = len(all_splits)\n",
        "third = total_documents // 3\n",
        "\n",
        "for i, document in enumerate(all_splits):\n",
        "    if i < third:\n",
        "        document.metadata[\"section\"] = \"beginning\"\n",
        "    elif i < 2 * third:\n",
        "        document.metadata[\"section\"] = \"middle\"\n",
        "    else:\n",
        "        document.metadata[\"section\"] = \"end\"\n",
        "\n",
        "\n",
        "all_splits[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2WQsp2SiQNX",
        "outputId": "531773e1-7327-4edf-b15e-146650f8dc92"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
              " 'start_index': 8,\n",
              " 'text': 'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory',\n",
              " 'section': 'beginning'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 2\n"
      ],
      "metadata": {
        "id": "-zNU6mkwxBhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --upgrade --quiet langgraph langchain-community beautifulsoup4"
      ],
      "metadata": {
        "id": "Bq3CwIjGvPGU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "# Load and chunk contents of the blog\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "X1_UwSGsvV3E"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index chunks\n",
        "_ = vector_store.add_documents(documents=all_splits)"
      ],
      "metadata": {
        "id": "VtFm1DnIvXrT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)"
      ],
      "metadata": {
        "id": "FewitqmBvZdl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve(query: str):\n",
        "    \"\"\"Retrieve information related to a query.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs"
      ],
      "metadata": {
        "id": "Unxh_LaJvbNI"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
        "def query_or_respond(state: MessagesState):\n",
        "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "    llm_with_tools = llm.bind_tools([retrieve])\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # MessagesState appends messages to state instead of overwriting\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Step 2: Execute the retrieval.\n",
        "tools = ToolNode([retrieve])\n",
        "\n",
        "\n",
        "# Step 3: Generate a response using the retrieved content.\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"Generate answer.\"\"\"\n",
        "    # Get generated ToolMessages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # Format into prompt\n",
        "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "    system_message_content = (\n",
        "        \"You are an assistant for question-answering tasks. \"\n",
        "        \"Use the following pieces of retrieved context to answer \"\n",
        "        \"the question. If you don't know the answer, say that you \"\n",
        "        \"don't know. Use three sentences maximum and keep the \"\n",
        "        \"answer concise.\"\n",
        "        \"\\n\\n\"\n",
        "        f\"{docs_content}\"\n",
        "    )\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
        "\n",
        "    # Run\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "tIgJ1dq_vdCv"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "graph_builder.add_node(query_or_respond)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(\"query_or_respond\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"query_or_respond\",\n",
        "    tools_condition,\n",
        "    {END: END, \"tools\": \"tools\"},\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "pSAkvRf3vfpN"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ZsGbyiRfvhXy",
        "outputId": "f1bf81e3-e5d9-4d4d-c17c-b7d015418fed"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Hello\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsQdLLJmvkdi",
        "outputId": "859d34dd-9a33-460b-fdc5-b4b79662a5de"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"What is Task Decomposition?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_GAyQDgvnOy",
        "outputId": "62219007-f743-4634-aabf-e27a2a6997cc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is Task Decomposition?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_MiYjCsF6XgFtN1k7q407Eqpm)\n",
            " Call ID: call_MiYjCsF6XgFtN1k7q407Eqpm\n",
            "  Args:\n",
            "    query: Task Decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Task Decomposition is a method where complex tasks are broken down into smaller, more manageable steps. This approach, often facilitated by the Chain of Thought (CoT) prompting technique, encourages models to \"think step by step,\" enhancing their performance on intricate tasks. It also provides insights into the model's reasoning process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Specify an ID for the thread\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ],
      "metadata": {
        "id": "pQYXzy0qvr-a"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"What is Task Decomposition?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIVZ2ODevthQ",
        "outputId": "11e06665-2d4e-4167-dda6-7b8a0e8f6693"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is Task Decomposition?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_dDnMEj9XdRojLWjgV2LTaZz3)\n",
            " Call ID: call_dDnMEj9XdRojLWjgV2LTaZz3\n",
            "  Args:\n",
            "    query: Task Decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Task Decomposition is a process in which complex tasks are broken down into smaller, more manageable steps. It utilizes the Chain of Thought (CoT) technique, instructing models to \"think step by step\" to enhance performance on intricate tasks. This transformation helps clarify the model's thinking process and allows for easier execution of tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Can you look up some common ways of doing it?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st1fkHMIvwRo",
        "outputId": "eb6666d8-1310-4939-afa7-cf78b196e6cd"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Can you look up some common ways of doing it?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_CvKd5RaJXMQmhilDYo4AoSPV)\n",
            " Call ID: call_CvKd5RaJXMQmhilDYo4AoSPV\n",
            "  Args:\n",
            "    query: common ways of task decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
      ],
      "metadata": {
        "id": "MZG__b14v3qQ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "70bzBtqTv-Za",
        "outputId": "9f661e60-f72d-4b56-f36f-246786c6935f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
        "\n",
        "input_message = (\n",
        "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
        "    \"Once you get the answer, look up common extensions of that method.\"\n",
        ")\n",
        "\n",
        "for event in agent_executor.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYGiCimiwAXx",
        "outputId": "d4e70078-b263-47d2-c2a4-d8b9e00f8ba6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is the standard method for Task Decomposition?\n",
            "\n",
            "Once you get the answer, look up common extensions of that method.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_msB7nNZSPdqG7xrANVury285)\n",
            " Call ID: call_msB7nNZSPdqG7xrANVury285\n",
            "  Args:\n",
            "    query: standard method for Task Decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192.0}\n",
            "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_5dEtaifgIdG7w5SldGAVG0sl)\n",
            " Call ID: call_5dEtaifgIdG7w5SldGAVG0sl\n",
            "  Args:\n",
            "    query: common extensions of Task Decomposition method\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "### Standard Method for Task Decomposition\n",
            "\n",
            "The standard method for task decomposition involves breaking down a complex task into smaller, more manageable sub-tasks. This can be accomplished in several ways:\n",
            "\n",
            "1. **Using LLMs with Prompts**: You can prompt language models (LLMs) with instructions such as \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\" to receive structured breakdowns of tasks.\n",
            "\n",
            "2. **Task-Specific Instructions**: For example, using a prompt like \"Write a story outline.\" helps in generating specific sub-tasks related to writing a novel.\n",
            "\n",
            "3. **Human Inputs**: Engaging human input to identify and articulate the components of the task can also play a role in effective decomposition.\n",
            "\n",
            "### Common Extensions of Task Decomposition\n",
            "\n",
            "A notable extension to the task decomposition method is the **Tree of Thoughts** (Yao et al. 2023), which expands upon the concept of Chain of Thought (CoT) reasoning. This method explores multiple reasoning possibilities at each step, generating several thoughts per step and organizing them in a tree structure. The search process within this framework can utilize either:\n",
            "\n",
            "- **Breadth-First Search (BFS)** or \n",
            "- **Depth-First Search (DFS)** \n",
            "\n",
            "to evaluate each state using classifiers or majority votes through prompts. This allows for more nuanced and comprehensive breakdowns of tasks, integrating various possible pathways for reasoning and problem-solving.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRUEBAS CON RESPECTO A LOS EJEMPLOS ANTERIORES"
      ],
      "metadata": {
        "id": "Ernn2PJWwUaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "# Load and chunk contents of the blog\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://www.hseblog.com/fire-detectors/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "wO2Bcpm7wXS_"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index chunks\n",
        "_ = vector_store.add_documents(documents=all_splits)"
      ],
      "metadata": {
        "id": "MeymA5VKyFMH"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)"
      ],
      "metadata": {
        "id": "yll8-s8WyG6n"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve(query: str):\n",
        "    \"\"\"Retrieve information related to a query.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs"
      ],
      "metadata": {
        "id": "mOkgwQmnyMLx"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
        "def query_or_respond(state: MessagesState):\n",
        "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "    llm_with_tools = llm.bind_tools([retrieve])\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # MessagesState appends messages to state instead of overwriting\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Step 2: Execute the retrieval.\n",
        "tools = ToolNode([retrieve])\n",
        "\n",
        "\n",
        "# Step 3: Generate a response using the retrieved content.\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"Generate answer.\"\"\"\n",
        "    # Get generated ToolMessages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # Format into prompt\n",
        "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "    system_message_content = (\n",
        "        \"You are an assistant for question-answering tasks. \"\n",
        "        \"Use the following pieces of retrieved context to answer \"\n",
        "        \"the question. If you don't know the answer, say that you \"\n",
        "        \"don't know. Use three sentences maximum and keep the \"\n",
        "        \"answer concise.\"\n",
        "        \"\\n\\n\"\n",
        "        f\"{docs_content}\"\n",
        "    )\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
        "\n",
        "    # Run\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "JwLaroBzyQh0"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "graph_builder.add_node(query_or_respond)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(\"query_or_respond\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"query_or_respond\",\n",
        "    tools_condition,\n",
        "    {END: END, \"tools\": \"tools\"},\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "NBpRiaIyyV5Z"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Hola\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ-EeP_MybEf",
        "outputId": "288db387-135e-4b03-e27e-52a406201279"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hola\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "¡Hola! ¿Cómo puedo ayudarte hoy?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"What are fire detectors?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MOHy0A_ye1h",
        "outputId": "262b3bfe-0909-4f72-980f-1ec4a1ab2a4e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What are fire detectors?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_OgyqphXWrh4dzJBCKmeBCZh5)\n",
            " Call ID: call_OgyqphXWrh4dzJBCKmeBCZh5\n",
            "  Args:\n",
            "    query: What are fire detectors?\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\n",
            "Generative Agents Simulation#\n",
            "Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\n",
            "The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\n",
            "Generative Agents Simulation#\n",
            "Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\n",
            "The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Fire detectors are devices designed to detect the presence of fire or smoke and alert individuals to potential danger. They typically use various technologies, such as ionization or photoelectric sensors, to sense smoke, heat, or flames. Once activated, fire detectors send out alarms to warn occupants, enabling timely evacuation and response.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Specify an ID for the thread\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ],
      "metadata": {
        "id": "sl-ptwWGytHb"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"why are they important?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bcQH3nryw90",
        "outputId": "e295a1b4-dd1b-4f94-f44d-0d3b88ab0b61"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "why are they important?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_wTzGPpeLQfhj1ltzqKyfwXES)\n",
            " Call ID: call_wTzGPpeLQfhj1ltzqKyfwXES\n",
            "  Args:\n",
            "    query: importance of various concepts or entities\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 25201.0}\n",
            "Content: Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
            "\n",
            "Each element is an observation, an event directly provided by the agent.\n",
            "- Inter-agent communication can trigger new natural language statements.\n",
            "\n",
            "\n",
            "Retrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\n",
            "\n",
            "Recency: recent events have higher scores\n",
            "Importance: distinguish mundane from core memories. Ask LM directly.\n",
            "Relevance: based on how related it is to the current situation / query.\n",
            "\n",
            "\n",
            "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
            "\n",
            "Each element is an observation, an event directly provided by the agent.\n",
            "- Inter-agent communication can trigger new natural language statements.\n",
            "\n",
            "\n",
            "Retrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\n",
            "\n",
            "Recency: recent events have higher scores\n",
            "Importance: distinguish mundane from core memories. Ask LM directly.\n",
            "Relevance: based on how related it is to the current situation / query.\n",
            "\n",
            "\n",
            "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Memory streams are important because they allow agents to retain and record their experiences, which can enhance their decision-making and behavior over time. The retrieval model helps prioritize information based on recency, importance, and relevance, ensuring agents respond appropriately to current situations. Additionally, the reflection mechanism enables agents to synthesize past experiences into higher-level inferences, guiding their future actions effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
      ],
      "metadata": {
        "id": "F1_Vv6TYzrd4"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
        "\n",
        "input_message = (\n",
        "    \"What are the different types of fire detectors, and how do they work?\"\n",
        ")\n",
        "\n",
        "for event in agent_executor.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXzAxP96zkZe",
        "outputId": "d3905eec-bb88-4ece-ce57-f1aca103b564"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What are the different types of fire detectors, and how do they work?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_6K5CVbtEjIkQbu4w2K0t7nC6)\n",
            " Call ID: call_6K5CVbtEjIkQbu4w2K0t7nC6\n",
            "  Args:\n",
            "    query: types of fire detectors and how they work\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\n",
            "Component Two: Memory#\n",
            "(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\n",
            "Types of Memory#\n",
            "Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\n",
            "\n",
            "\n",
            "Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\n",
            "Component Two: Memory#\n",
            "(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\n",
            "Types of Memory#\n",
            "Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\n",
            "\n",
            "\n",
            "Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_CadF30WqdLg3LlUaF9zy1X4F)\n",
            " Call ID: call_CadF30WqdLg3LlUaF9zy1X4F\n",
            "  Args:\n",
            "    query: different kinds of fire detectors and their mechanisms\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\n",
            "Component Two: Memory#\n",
            "(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\n",
            "Types of Memory#\n",
            "Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\n",
            "\n",
            "\n",
            "Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "Content: Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\n",
            "Component Two: Memory#\n",
            "(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\n",
            "Types of Memory#\n",
            "Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\n",
            "\n",
            "\n",
            "Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I wasn't able to find specific information about different types of fire detectors and their mechanisms. However, I can provide a summary based on general knowledge.\n",
            "\n",
            "### Types of Fire Detectors\n",
            "\n",
            "1. **Ionization Smoke Detectors**:\n",
            "   - **How They Work**: These detectors use a small amount of radioactive material that ionizes air, creating a current. When smoke enters the chamber, it disrupts this current, triggering the alarm.\n",
            "   - **Best For**: Fast-flaming fires, such as those caused by flammable liquids or paper.\n",
            "\n",
            "2. **Photoelectric Smoke Detectors**:\n",
            "   - **How They Work**: These detectors use a light beam and a light sensor. When smoke enters the chamber, it scatters the light beam, causing the sensor to trigger the alarm.\n",
            "   - **Best For**: Smoldering fires with a lot of smoke, such as burning furniture or bedding.\n",
            "\n",
            "3. **Heat Detectors**:\n",
            "   - **How They Work**: These devices detect changes in temperature. They can be fixed temperature detectors that trigger an alarm at a specific temperature or rate-of-rise detectors that trigger an alarm if the temperature rises rapidly.\n",
            "   - **Best For**: Areas where smoke detectors might cause false alarms, like kitchens or garages.\n",
            "\n",
            "4. **Combination Detectors**:\n",
            "   - **How They Work**: These devices combine the technology of smoke and heat detection. \n",
            "   - **Best For**: Providing comprehensive fire protection by detecting different types of fires.\n",
            "\n",
            "5. **Multi-Criteria Detectors**:\n",
            "   - **How They Work**: These detectors use multiple sensing technologies (e.g., both smoke and heat). They analyze signals from both components to reduce false alarms while maintaining a quick response to real fires.\n",
            "   - **Best For**: Complex environments where different types of fire risks exist.\n",
            "\n",
            "6. **Gas Detectors**:\n",
            "   - **How They Work**: These detect the presence of certain gases (like carbon monoxide, which can indicate a fire). They are less common as standalone fire detectors but can serve as part of a fire detection system.\n",
            "   - **Best For**: Areas where flammable gases are a concern.\n",
            "\n",
            "### Summary\n",
            "Choosing the right type of fire detector depends on the specific risks of the environment. Ionization and photoelectric detectors are commonly used in homes, while heat detectors may be preferred in areas susceptible to false alarms. Multi-criteria detectors can provide a balanced approach by combining various detection methods.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3OFXpeN8yT0e"
      }
    }
  ]
}